{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fd23c3e",
   "metadata": {},
   "source": [
    "## Applying Artificial Neural Network Algorithms to the Problem (Stock Time Series Forecasting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08c9a97",
   "metadata": {},
   "source": [
    "# HYBRID MODEL X2 v04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00deeef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x161c43d0e90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.volatility import BollingerBands\n",
    "from ta.trend import MACD\n",
    "from scipy.stats import zscore\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from tensorflow.keras.layers import Input, Conv1D, LSTM, Dense, concatenate, Dropout, concatenate, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#xXx############################################################################################xXx#\n",
    "# Function to preprocess and clean the dataset dynamically\n",
    "def preprocess_data(ticker, start, end, n_timesteps=10, model_type='LSTM'):\n",
    "    # Download historical data\n",
    "    df = yf.download(ticker, start=start, end=end)\n",
    "    \n",
    "    # Preprocess the data\n",
    "    df['Date'] = pd.to_datetime(df.index)\n",
    "    df['Date'] = df['Date'].apply(lambda date: date.timestamp())\n",
    "    \n",
    "    # Remove noise and outliers\n",
    "    z_scores = zscore(df[['Open', 'High', 'Low', 'Close', 'Volume']])\n",
    "    df = df[(z_scores < 3).all(axis=1)]\n",
    "\n",
    "    # Feature engineering\n",
    "    df['Price_Change_Pct'] = df['Close'].pct_change()\n",
    "    df['Log_Returns'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "    df['50d_MA'] = df['Close'].rolling(window=50).mean()\n",
    "    df['200d_MA'] = df['Close'].rolling(window=200).mean()\n",
    "\n",
    "    # Technical indicators\n",
    "    rsi_indicator = RSIIndicator(df['Close'], window=14)\n",
    "    df['RSI'] = rsi_indicator.rsi()\n",
    "    bb_indicator = BollingerBands(df['Close'], window=20)\n",
    "    df['Bollinger_Bands'] = bb_indicator.bollinger_mavg()\n",
    "    macd_indicator = MACD(df['Close'], window_slow=26, window_fast=12)\n",
    "    df['MACD'] = macd_indicator.macd()\n",
    "\n",
    "    # Remove NA values after feature engineering\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Split the data into features and target\n",
    "    X = df[['Price_Change_Pct', 'Log_Returns', '50d_MA', '200d_MA', 'RSI', 'Bollinger_Bands', 'MACD']]\n",
    "    y = df['Close']\n",
    "\n",
    "    return X, y\n",
    "\n",
    "class ReshapeForModel(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_timesteps=10, model_type='LSTM'):\n",
    "        self.n_timesteps = n_timesteps\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        reshaped_data = []\n",
    "\n",
    "        # Create rolling windows of size 'n_timesteps'\n",
    "        for i in range(n_samples - self.n_timesteps + 1):\n",
    "            reshaped_data.append(X[i:i + self.n_timesteps])\n",
    "        \n",
    "        reshaped_data = np.array(reshaped_data)\n",
    "\n",
    "        # Do NOT add channel dimension for CNN, as Conv1D expects 3D input (n_samples, n_timesteps, n_features)\n",
    "        if self.model_type == 'CNN':\n",
    "            return reshaped_data  # Shape: (n_samples, n_timesteps, n_features)\n",
    "        return reshaped_data  # Same for LSTM\n",
    "\n",
    "\n",
    "# Dynamic pipeline for preprocessing, scaling, and reshaping\n",
    "def create_dynamic_pipeline(n_timesteps=10, model_type='LSTM'):\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),           # Handle missing values\n",
    "        ('scaler', MinMaxScaler(feature_range=(0, 1))),        # Normalize data\n",
    "        ('reshape', ReshapeForModel(n_timesteps=n_timesteps, model_type=model_type))  # Reshape for model\n",
    "    ])\n",
    "    return pipeline\n",
    "\n",
    "# LSTM model creation\n",
    "def create_lstm_model(n_timesteps, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))  # Assuming it's a regression task\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# CNN model creation\n",
    "def create_cnn_model(n_timesteps, n_features):\n",
    "    model = Sequential()\n",
    "    # Conv1D expects 3D input: (n_samples, n_timesteps, n_features)\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))  # Assuming it's a regression task\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Combination\n",
    "def create_hybrid_model(n_timesteps, n_features):\n",
    "    # CNN branch\n",
    "    cnn_input = Input(shape=(n_timesteps, n_features))\n",
    "    cnn_branch = Conv1D(filters=64, kernel_size=3, activation='relu')(cnn_input)\n",
    "    cnn_branch = Flatten()(cnn_branch)  # Flatten to 2D shape (None, units)\n",
    "    \n",
    "    # LSTM branch\n",
    "    lstm_input = Input(shape=(n_timesteps, n_features))\n",
    "    lstm_branch = LSTM(50, activation='relu')(lstm_input)  # Already 2D output (None, 50)\n",
    "    \n",
    "    # Combine CNN and LSTM branches\n",
    "    combined = concatenate([cnn_branch, lstm_branch])\n",
    "    \n",
    "    # Add a Dropout layer for regularization\n",
    "    combined = Dropout(0.2)(combined)\n",
    "    \n",
    "    # Output layer (for regression)\n",
    "    output = Dense(1)(combined)\n",
    "    \n",
    "    # Build model\n",
    "    model = Model(inputs=[cnn_input, lstm_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return model\n",
    "#xXx############################################################################################xXx#\n",
    "\n",
    "# Set up the pipeline and models\n",
    "ticker = \"PGR\"\n",
    "start = \"2000-01-01\"\n",
    "end = (datetime.today() - timedelta(days=5)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Preprocess and split the data\n",
    "X, y = preprocess_data(ticker, start=start, end=end)\n",
    "\n",
    "# Create the pipeline for LSTM\n",
    "pipeline_lstm = create_dynamic_pipeline(n_timesteps=10, model_type='LSTM')\n",
    "X_lstm_processed = pipeline_lstm.fit_transform(X)\n",
    "\n",
    "# Train your LSTM model\n",
    "lstm_model = create_lstm_model(n_timesteps=10, n_features=X_lstm_processed.shape[2])\n",
    "lstm_model.fit(X_lstm_processed, y[9:], epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "# Create the pipeline for CNN\n",
    "pipeline_cnn = create_dynamic_pipeline(n_timesteps=10, model_type='CNN')\n",
    "X_cnn_processed = pipeline_cnn.fit_transform(X)\n",
    "\n",
    "# Train your CNN model\n",
    "cnn_model = create_cnn_model(n_timesteps=10, n_features=X_cnn_processed.shape[2])\n",
    "cnn_model.fit(X_cnn_processed, y[9:], epochs=10, batch_size=32, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13a5fe93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x161b2082250>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure both have the same shape before feeding them into the hybrid model\n",
    "assert X_lstm_processed.shape == X_cnn_processed.shape\n",
    "\n",
    "# Create the hybrid model\n",
    "hybrid_model = create_hybrid_model(n_timesteps=10, n_features=X.shape[1])\n",
    "\n",
    "# Train the hybrid model\n",
    "hybrid_model.fit([X_cnn_processed, X_lstm_processed], y[9:], epochs=10, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f41c159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "LSTM Model - MSE: 37.413965194261536, MAE: 5.366988923814562\n"
     ]
    }
   ],
   "source": [
    "# Split your data into train and test sets (if not already split)\n",
    "X_train_lstm, X_test_lstm, y_train, y_test = train_test_split(X_lstm_processed, y[9:], test_size=0.2, shuffle=False)\n",
    "\n",
    "# Train your LSTM model\n",
    "lstm_model.fit(X_train_lstm, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "# Predict with LSTM\n",
    "y_pred_lstm = lstm_model.predict(X_test_lstm)\n",
    "\n",
    "# Calculate scores for LSTM\n",
    "mse_lstm = mean_squared_error(y_test, y_pred_lstm)\n",
    "mae_lstm = mean_absolute_error(y_test, y_pred_lstm)\n",
    "\n",
    "print(f\"LSTM Model - MSE: {mse_lstm}, MAE: {mae_lstm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27ba36a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    }
   ],
   "source": [
    "# Split your data into train and test sets for CNN\n",
    "X_train_cnn, X_test_cnn, y_train, y_test = train_test_split(X_cnn_processed, y[9:], test_size=0.2, shuffle=False)\n",
    "\n",
    "# Train your CNN model\n",
    "cnn_model.fit(X_train_cnn, y_train, epochs=10, batch_size=32,verbose=0)\n",
    "\n",
    "# Predict with CNN\n",
    "y_pred_cnn = cnn_model.predict(X_test_cnn)\n",
    "\n",
    "# Calculate scores for CNN\n",
    "#mse_cnn = mean_squared_error(y_test, y_pred_cnn)\n",
    "#mae_cnn = mean_absolute_error(y_test, y_pred_cnn)\n",
    "\n",
    "#print(f\"CNN Model - MSE: {mse_cnn}, MAE: {mae_cnn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db26eb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Hybrid Model - MSE: 13.309948956949434, MAE: 2.7983120481173196\n"
     ]
    }
   ],
   "source": [
    "# Split your data into train and test sets for both LSTM and CNN inputs (hybrid)\n",
    "X_train_lstm, X_test_lstm, y_train, y_test = train_test_split(X_lstm_processed, y[9:], test_size=0.2, shuffle=False)\n",
    "X_train_cnn, X_test_cnn, _, _ = train_test_split(X_cnn_processed, y[9:], test_size=0.2, shuffle=False)\n",
    "\n",
    "# Train the Hybrid model\n",
    "hybrid_model.fit([X_train_cnn, X_train_lstm], y_train, epochs=10, batch_size=32,verbose=0)\n",
    "\n",
    "# Predict with the Hybrid model\n",
    "y_pred_hybrid = hybrid_model.predict([X_test_cnn, X_test_lstm])\n",
    "\n",
    "# Calculate scores for the Hybrid model\n",
    "mse_hybrid = mean_squared_error(y_test, y_pred_hybrid)\n",
    "mae_hybrid = mean_absolute_error(y_test, y_pred_hybrid)\n",
    "\n",
    "print(f\"Hybrid Model - MSE: {mse_hybrid}, MAE: {mae_hybrid}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a099c15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Models:\n",
      "LSTM Model - MSE: 37.413965194261536, MAE: 5.366988923814562\n",
      "Hybrid Model - MSE: 13.309948956949434, MAE: 2.7983120481173196\n"
     ]
    }
   ],
   "source": [
    "print(f\"Comparison of Models:\")\n",
    "print(f\"LSTM Model - MSE: {mse_lstm}, MAE: {mae_lstm}\")\n",
    "#print(f\"CNN Model - MSE: {mse_cnn}, MAE: {mae_cnn}\")\n",
    "print(f\"Hybrid Model - MSE: {mse_hybrid}, MAE: {mae_hybrid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb71be4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Model - R2: 0.9453604716601987\n",
      "Hybrid Model - R2: 0.9805620887960281\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_lstm = r2_score(y_test, y_pred_lstm)\n",
    "#r2_cnn = r2_score(y_test, y_pred_cnn)\n",
    "r2_hybrid = r2_score(y_test, y_pred_hybrid)\n",
    "\n",
    "print(f\"LSTM Model - R2: {r2_lstm}\")\n",
    "#print(f\"CNN Model - R2: {r2_cnn}\")\n",
    "print(f\"Hybrid Model - R2: {r2_hybrid}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d338ede9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.0592\n",
      "Epoch 2/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.0994\n",
      "Epoch 3/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.1035\n",
      "Epoch 4/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.5063\n",
      "Epoch 5/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.7910\n",
      "Epoch 6/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.0905\n",
      "Epoch 7/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.4853\n",
      "Epoch 8/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.2163\n",
      "Epoch 9/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 7.0324\n",
      "Epoch 10/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.0513\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "LSTM Model - MSE: 10.944246638667563, MAE: 2.502556304136912, R2: 0.9840169714365649\n",
      "Epoch 1/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9639\n",
      "Epoch 2/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2438\n",
      "Epoch 3/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.8057\n",
      "Epoch 4/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9217\n",
      "Epoch 5/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0934\n",
      "Epoch 6/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0773\n",
      "Epoch 7/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7267\n",
      "Epoch 8/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9391\n",
      "Epoch 9/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0389\n",
      "Epoch 10/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7949\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 1/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.6719\n",
      "Epoch 2/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.5990\n",
      "Epoch 3/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.6039\n",
      "Epoch 4/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.5548\n",
      "Epoch 5/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4061\n",
      "Epoch 6/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4540\n",
      "Epoch 7/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.3799\n",
      "Epoch 8/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.2689\n",
      "Epoch 9/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.4906\n",
      "Epoch 10/10\n",
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.2552\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Hybrid Model - MSE: 13.328114504532046, MAE: 2.8526855773395963, R2: 0.9805355597460653\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Split your data for LSTM\n",
    "X_train_lstm, X_test_lstm, y_train, y_test = train_test_split(X_lstm_processed, y[9:], test_size=0.2, shuffle=False)\n",
    "\n",
    "# Train your LSTM model\n",
    "lstm_model.fit(X_train_lstm, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Predict with LSTM\n",
    "y_pred_lstm = lstm_model.predict(X_test_lstm)\n",
    "\n",
    "# Calculate scores for LSTM\n",
    "mse_lstm = mean_squared_error(y_test, y_pred_lstm)\n",
    "mae_lstm = mean_absolute_error(y_test, y_pred_lstm)\n",
    "r2_lstm = r2_score(y_test, y_pred_lstm)\n",
    "\n",
    "print(f\"LSTM Model - MSE: {mse_lstm}, MAE: {mae_lstm}, R2: {r2_lstm}\")\n",
    "\n",
    "\n",
    "# Split your data for CNN\n",
    "X_train_cnn, X_test_cnn, _, _ = train_test_split(X_cnn_processed, y[9:], test_size=0.2, shuffle=False)\n",
    "\n",
    "# Train your CNN model\n",
    "cnn_model.fit(X_train_cnn, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Predict with CNN\n",
    "y_pred_cnn = cnn_model.predict(X_test_cnn)\n",
    "\n",
    "# Calculate scores for CNN\n",
    "y_pred_cnn = np.squeeze(y_pred_cnn)\n",
    "#mse_cnn = np.mean((y_test - y_pred_cnn) ** 2)\n",
    "#mae_cnn = np.mean(np.abs(y_test - y_pred_cnn))\n",
    "#r2_cnn = np.corrcoef(y_test, y_pred_cnn)[0, 1] ** 2\n",
    "\n",
    "#print(f\"CNN Model - MSE: {mse_cnn}, MAE: {mae_cnn}, R2: {r2_cnn}\")\n",
    "\n",
    "\n",
    "# Split your data for the hybrid model (both LSTM and CNN inputs)\n",
    "X_train_lstm, X_test_lstm, y_train, y_test = train_test_split(X_lstm_processed, y[9:], test_size=0.2, shuffle=False)\n",
    "X_train_cnn, X_test_cnn, _, _ = train_test_split(X_cnn_processed, y[9:], test_size=0.2, shuffle=False)\n",
    "\n",
    "# Train the Hybrid model\n",
    "hybrid_model.fit([X_train_cnn, X_train_lstm], y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Predict with the Hybrid model\n",
    "y_pred_hybrid = hybrid_model.predict([X_test_cnn, X_test_lstm])\n",
    "\n",
    "# Calculate scores for Hybrid model\n",
    "mse_hybrid = mean_squared_error(y_test, y_pred_hybrid)\n",
    "mae_hybrid = mean_absolute_error(y_test, y_pred_hybrid)\n",
    "r2_hybrid = r2_score(y_test, y_pred_hybrid)\n",
    "\n",
    "print(f\"Hybrid Model - MSE: {mse_hybrid}, MAE: {mae_hybrid}, R2: {r2_hybrid}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
